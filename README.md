# Procesamiento del lenguaje natural II

Introducci√≥n

La materia Procesamiento del Lenguaje Natural II forma parte del plan del Master en Inteligencia Artificial (MIA) de la UBA y constituye la base te√≥rica y pr√°ctica para comprender c√≥mo las computadoras procesan, representan y generan lenguaje humano.

---

El Trabajo Pr√°ctico 1 de la materia Procesamiento del Lenguaje Natural II tiene como objetivo introducir al alumno en los fundamentos pr√°cticos del an√°lisis del lenguaje natural utilizando t√©cnicas cl√°sicas y modelos de aprendizaje autom√°tico.

Este trabajo sienta las bases del PLN moderno, reforzando conceptos esenciales como:

  * procesamiento y limpieza de texto
  * tokenizaci√≥n
  * representaci√≥n vectorial
  * embeddings tradicionales,
  * modelos de clasificaci√≥n de texto,
  * entrenamiento supervisado,
  * evaluaci√≥n de m√©tricas,
  * an√°lisis de resultados.

üéØ Objetivos del TP1

  * Comprender y aplicar t√©cnicas de preprocesamiento de texto.
  * Analizar distintas representaciones vectoriales:
      * Bag of Words (BoW)
      * TF-IDF
      * Embeddings distribucionales

  * Entrenar modelos supervisados de clasificaci√≥n.
  * Evaluar desempe√±o mediante m√©tricas est√°ndar (accuracy, f1-score, p√©rdida).
  * Explorar distintos hiperpar√°metros y observar su impacto.
  * Implementar ciclos de entrenamiento utilizando un trainer modular (seg√∫n trainer.py).
  * Realizar an√°lisis experimental a trav√©s de notebooks (seg√∫n trabajo_practico_1.ipynb).

üõ†Ô∏è Tecnolog√≠as y librer√≠as utilizadas en el TP1

El trabajo pr√°ctico incorpora un conjunto de herramientas orientadas al PLN cl√°sico y aprendizaje autom√°tico:

‚úîÔ∏è Procesamiento de texto

   * NLTK
   * spaCy
   * regex
   * Normalizaci√≥n y tokenizaci√≥n

‚úîÔ∏è Representaci√≥n vectorial

   * scikit-learn (CountVectorizer, TF-IDF)
   * Embeddings b√°sicos utilizados en modelos lineales o feed-forward

‚úîÔ∏è Modelado y entrenamiento

   * PyTorch ‚Äî para modelos simples de clasificaci√≥n
   * trainer.py ‚Äî m√≥dulo propio para:
     * entrenamiento estructurado
     * early stopping
     * evaluaci√≥n
     * m√©tricas
     * manejo de batches y optimizaci√≥n

‚úîÔ∏è Experimentaci√≥n

   * Jupyter Notebook (trabajo_practico_1.ipynb)
     * an√°lisis exploratorio
     * experimentos
     * comparaci√≥n de modelos
     * reflexiones finales

üìÑ Resultado del TP1

El resultado final es un pipeline completo que abarca:

 1. Lectura y procesamiento del corpus
 2 .Vectorizaci√≥n del texto mediante m√©todos cl√°sicos
 3. Entrenamiento de un modelo de clasificaci√≥n usando PyTorch
 4. Implementaci√≥n de un ‚Äútrainer‚Äù modular para facilitar experimentos
 5. Evaluaci√≥n mediante m√©tricas y an√°lisis de desempe√±o

---

üìù Trabajo Pr√°ctico 2 ‚Äî Chatbot con RAG (Retrieval-Augmented Generation)

El objetivo del TP2 es implementar un chatbot que utilice informaci√≥n externa almacenada en una base vectorial para responder preguntas, aplicando la arquitectura RAG (Retrieval-Augmented Generation).

El sistema debe ser capaz de:

 * Leer y procesar un documento PDF (en este caso, el CV del alumno).
 * Limpiar y segmentar el texto en fragmentos (chunking).
 * Generar embeddings para cada fragmento del CV.
 * Almacenar esos embeddings en una base vectorial.
 * Recuperar los fragmentos m√°s relevantes ante una consulta.
 * Utilizar un modelo generativo para construir una respuesta final basada en el contexto recuperado.

‚úîÔ∏è Tecnolog√≠as y librer√≠as utilizadas

  * Python 3.11
  * Streamlit ‚Äî interfaz gr√°fica para el chatbot
  * PyPDF2 / pdfminer.six ‚Äî extracci√≥n de texto desde PDF
  * Pinecone ‚Äî base vectorial utilizada para indexaci√≥n sem√°ntica
  * Sentence-Transformers / BGE / MPNet ‚Äî modelos de embeddings
  * Groq (Llama 3) ‚Äî modelo generativo para la respuesta final
  * dotenv ‚Äî manejo de claves y variables de entorno
  * Similitud coseno / b√∫squeda k-NN ‚Äî mecanismo de recuperaci√≥n

‚úîÔ∏è Flujo general del TP1

1. Ingesti√≥n del CV

  * Lectura del PDF
  * Limpieza del texto
  * Segmentaci√≥n en chunks
  * Generaci√≥n de embeddings
  * Subida a Pinecone

2. Recuperaci√≥n de informaci√≥n (Retriever)

  * Para cada pregunta del usuario
  * Se generan embeddings de la consulta
  * Se buscan los chunks m√°s cercanos en la base vectorial

3. Generaci√≥n de respuesta (RAG)

  * Se construye un contexto a partir de los chunks recuperados
  * Se env√≠a el contexto + pregunta al modelo
  * El modelo genera una respuesta fundamentada

‚úîÔ∏è Resultado del TP2

El resultado final es un chatbot funcional que responde preguntas sobre el CV del alumno utilizando:

  * Recuperaci√≥n sem√°ntica
  * Construcci√≥n de contexto
  * Generaci√≥n aumentada con LLM
  * Interfaz lista para usar desde Streamlit
  * El sistema garantiza respuestas precisas, fundamentadas y basadas directamente en la informaci√≥n del documento original.


‚úîÔ∏è Directorio

<img width="990" height="161" alt="image" src="https://github.com/user-attachments/assets/250f50bf-8c20-42e2-bdb9-d99e63a24120" />


